"""
2^4 Factorial Design ì‹¤í—˜ ì„¤ì • (context_provision ì œê±°)
ANOVA ê²°ê³¼: context_provisionì€ p=0.982ë¡œ íš¨ê³¼ ì—†ìŒ
"""

from typing import Dict, List

# ê¸°ë³¸ ì‹¤í—˜ ì„¤ì •
DEFAULT_EXPERIMENT_CONFIG = {
    'n_responses': 5,          # ì¡°ê±´ë‹¹ ì‘ë‹µ ìˆ˜ (3 â†’ 5ë¡œ ì¦ê°€)
    'temperature': 0.7,        # ì‘ë‹µ ìƒì„± ì˜¨ë„
    'max_tokens': 500,         # ìµœëŒ€ í† í° ìˆ˜
    'retry_attempts': 3,       # ì‹¤íŒ¨ì‹œ ì¬ì‹œë„ íšŸìˆ˜
    'delay_between_requests': 1 # ìš”ì²­ ê°„ ì§€ì—° (ì´ˆ)
}

# ì‹¤í—˜ ëª¨ë“œë³„ ì„¤ì • (context_provision ì œê±° â†’ 2^4 = 16 ì¡°í•©)
EXPERIMENT_MODES = {
    'demo': {
        'mode_name': 'ë°ëª¨ ì‹¤í—˜',
        'max_conditions': 12,  # 2^2 Ã— 3 ì¹´í…Œê³ ë¦¬
        'factors_to_test': ['prompt_language', 'model'],
        'questions_per_category': 1,
        'estimated_cost_usd': 0.03  # 5ê°œ ì‘ë‹µìœ¼ë¡œ ì¦ê°€
    },
    'test': {
        'mode_name': 'í…ŒìŠ¤íŠ¸ ì‹¤í—˜', 
        'max_conditions': 36,  # 2^3 Ã— 3 ì¹´í…Œê³ ë¦¬
        'factors_to_test': ['prompt_language', 'model', 'role_assignment'],
        'questions_per_category': 1,
        'estimated_cost_usd': 0.08  # 5ê°œ ì‘ë‹µìœ¼ë¡œ ì¦ê°€
    },
    'representative': {
        'mode_name': 'ëŒ€í‘œ ì„¤ê³„ (ìµœì í™”)',
        'max_conditions': 48,  # 2^4 Ã— 3 ì¹´í…Œê³ ë¦¬ (context_provision ì œê±°)
        'factors_to_test': ['all'],
        'questions_per_category': 1,
        'estimated_cost_usd': 0.32  # 5ê°œ ì‘ë‹µìœ¼ë¡œ ì¦ê°€
    },
    'full': {
        'mode_name': 'ì „ì²´ ì„¤ê³„ (ìµœì í™”)',
        'max_conditions': 336,  # 2^4 Ã— 21 ì§ˆë¬¸ (7ê°œÃ—3ì¹´í…Œê³ ë¦¬, context_provision ì œê±°)
        'factors_to_test': ['all'],
        'questions_per_category': 'all',
        'estimated_cost_usd': 2.24  # 7ê°œ ì§ˆë¬¸ Ã— 5ê°œ ì‘ë‹µ
    }
}

# OpenAI ëª¨ë¸ë³„ ë¹„ìš© (1000 í† í°ë‹¹ USD)
MODEL_COSTS = {
    'gpt-3.5-turbo': {
        'input': 0.0015,
        'output': 0.002
    },
    'gpt-4o-mini': {
        'input': 0.00015,
        'output': 0.0006
    }
}

def get_experiment_config(mode: str = 'demo') -> Dict:
    """
    ì‹¤í—˜ ëª¨ë“œì— ë”°ë¥¸ ì„¤ì • ë°˜í™˜
    
    Args:
        mode (str): ì‹¤í—˜ ëª¨ë“œ ('demo', 'test', 'representative', 'full')
        
    Returns:
        Dict: ì‹¤í—˜ ì„¤ì •
    """
    if mode not in EXPERIMENT_MODES:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹¤í—˜ ëª¨ë“œ: {mode}. ê°€ëŠ¥í•œ ëª¨ë“œ: {list(EXPERIMENT_MODES.keys())}")
    
    mode_config = EXPERIMENT_MODES[mode].copy()
    base_config = DEFAULT_EXPERIMENT_CONFIG.copy()
    
    # ì„¤ì • ë³‘í•©
    config = {**base_config, **mode_config}
    config['mode'] = mode
    
    return config

def estimate_experiment_cost(mode: str, n_responses: int = 3) -> Dict:
    """
    ì‹¤í—˜ ë¹„ìš© ì¶”ì •
    
    Args:
        mode (str): ì‹¤í—˜ ëª¨ë“œ
        n_responses (int): ì¡°ê±´ë‹¹ ì‘ë‹µ ìˆ˜
        
    Returns:
        Dict: ë¹„ìš© ì¶”ì • ì •ë³´
    """
    config = get_experiment_config(mode)
    
    # í‰ê·  í† í° ìˆ˜ ì¶”ì •
    avg_input_tokens = 150   # í”„ë¡¬í”„íŠ¸ í‰ê·  í† í°
    avg_output_tokens = 300  # ì‘ë‹µ í‰ê·  í† í°
    
    total_requests = config['max_conditions'] * n_responses
    
    # ëª¨ë¸ë³„ ë¹„ìš© ê³„ì‚° (gpt-3.5-turboì™€ gpt-4o-mini 50:50 ê°€ì •)
    gpt35_cost = (avg_input_tokens * MODEL_COSTS['gpt-3.5-turbo']['input'] + 
                  avg_output_tokens * MODEL_COSTS['gpt-3.5-turbo']['output']) / 1000
    
    gpt4o_mini_cost = (avg_input_tokens * MODEL_COSTS['gpt-4o-mini']['input'] + 
                       avg_output_tokens * MODEL_COSTS['gpt-4o-mini']['output']) / 1000
    
    avg_cost_per_request = (gpt35_cost + gpt4o_mini_cost) / 2
    total_cost = total_requests * avg_cost_per_request
    
    return {
        'mode': mode,
        'total_conditions': config['max_conditions'],
        'total_requests': total_requests,
        'avg_cost_per_request': avg_cost_per_request,
        'estimated_total_cost': total_cost,
        'breakdown': {
            'gpt-3.5-turbo_cost_per_request': gpt35_cost,
            'gpt-4o-mini_cost_per_request': gpt4o_mini_cost,
            'requests_per_model': total_requests // 2
        }
    }

def print_experiment_info(mode: str):
    """ì‹¤í—˜ ì •ë³´ ì¶œë ¥"""
    config = get_experiment_config(mode)
    cost_info = estimate_experiment_cost(mode, config['n_responses'])
    
    print(f"\nğŸ”¬ {config['mode_name']} ì •ë³´")
    print("=" * 50)
    print(f"ğŸ“Š ì‹¤í—˜ ì„¤ê³„: 2^4 Factorial Design")
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ìš”ì¸: {len(config['factors_to_test'])}ê°œ")
    
    if config['factors_to_test'] != ['all']:
        print(f"   - ìš”ì¸: {', '.join(config['factors_to_test'])}")
    else:
        print(f"   - ëª¨ë“  ìš”ì¸ (4ê°œ): prompt_language, model, role_assignment, explicitness")
        print(f"   - ì œê±°ëœ ìš”ì¸: context_provision (p=0.982, íš¨ê³¼ ì—†ìŒ)")
    
    print(f"ğŸ“Š ì´ ì¡°ê±´ ìˆ˜: {config['max_conditions']}")
    print(f"ğŸ“Š ì¡°ê±´ë‹¹ ì‘ë‹µ ìˆ˜: {config['n_responses']}")
    print(f"ğŸ“Š ì´ API ìš”ì²­: {cost_info['total_requests']}")
    print(f"ğŸ’° ì˜ˆìƒ ë¹„ìš©: ${cost_info['estimated_total_cost']:.3f}")

if __name__ == "__main__":
    print("ğŸ§ª 2^4 Factorial Design ì‹¤í—˜ ì„¤ì •")
    print("=" * 60)
    
    for mode in EXPERIMENT_MODES.keys():
        print_experiment_info(mode)
        print()
    
    print("ğŸ’¡ ì¶”ì²œ (ANOVA ìµœì í™” ê¸°ë°˜):")
    print("   - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: demo ëª¨ë“œ")
    print("   - ìš”ì¸ íš¨ê³¼ í™•ì¸: test ëª¨ë“œ") 
    print("   - íš¨ìœ¨ì  ë¶„ì„: representative ëª¨ë“œ (50% ë¹„ìš© ì ˆì•½)")
    print("   - ì™„ì „í•œ ì‹¤í—˜: full ëª¨ë“œ (50% ë¹„ìš© ì ˆì•½)")
    print("   âš¡ context_provision ì œê±°ë¡œ ëª¨ë“  ëª¨ë“œ ë¹„ìš© 50% ì ˆì•½!") 