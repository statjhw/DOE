"""
2^4 Factorial Design Power Analysis (context_provision ì œê±°)
Representative ëª¨ë“œ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì • ìƒ˜í”Œ í¬ê¸° ê²°ì •
ANOVA ê²°ê³¼: context_provisionì€ p=0.982ë¡œ íš¨ê³¼ ì—†ìŒ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from statsmodels.stats.power import FTestAnovaPower, ttest_power
import json
import ast
import glob
import os

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['Arial Unicode MS', 'AppleGothic', 'Malgun Gothic']
plt.rcParams['axes.unicode_minus'] = False

def load_representative_results():
    """Representative ëª¨ë“œ ì‹¤í—˜ ê²°ê³¼ ë¡œë“œ"""
    print("ğŸ“Š Representative ëª¨ë“œ ì‹¤í—˜ ê²°ê³¼ ë¡œë“œ ì¤‘...")
    
    # ì‹¤í—˜ ë°ì´í„° ë¡œë“œ
    df = pd.read_csv('factorial_results/factorial_experiment_data_representative_20250525_011508.csv')
    
    # factor_combination ë¬¸ìì—´ì„ íŒŒì‹±í•´ì„œ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„í•´
    print("ğŸ”§ ìš”ì¸ ì¡°í•© íŒŒì‹± ì¤‘...")
    
    # factor_combinationì„ JSONìœ¼ë¡œ íŒŒì‹± (ë¬¸ìì—´ì´ dict í˜•íƒœë¡œ ì €ì¥ë¨)
    factor_columns = []
    for idx, row in df.iterrows():
        try:
            # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            factor_dict = ast.literal_eval(row['factor_combination'])
            factor_columns.append(factor_dict)
        except:
            # ì‹¤íŒ¨í•˜ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬
            factor_columns.append({})
    
    # ìš”ì¸ë³„ë¡œ ì»¬ëŸ¼ ìƒì„±
    factor_df = pd.DataFrame(factor_columns)
    
    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ê³¼ ë³‘í•©
    for col in factor_df.columns:
        df[col] = factor_df[col]
    
    print(f"âœ… ìš”ì¸ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ: {list(factor_df.columns)}")
    
    # ë¶„ì„ ë°ì´í„° ë¡œë“œ
    analysis_df = pd.read_csv('factorial_results/factorial_analysis_data_representative_20250525_011508.csv')
    
    # ìš”ì•½ í†µê³„ ë¡œë“œ
    with open('factorial_results/factorial_experiment_summary_representative_20250525_011508.json', 'r', encoding='utf-8') as f:
        summary = json.load(f)
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"   - ì‹¤í—˜ ë°ì´í„°: {len(df)}ê°œ ê´€ì¸¡ì¹˜")
    print(f"   - ë¶„ì„ ë°ì´í„°: {len(analysis_df)}ê°œ ê´€ì¸¡ì¹˜")
    print(f"   - ìš”ì¸ ì»¬ëŸ¼: {[col for col in df.columns if col in ['prompt_language', 'model', 'role_assignment', 'explicitness']]}")
    
    return df, analysis_df, summary

def load_demo_results():
    """Demo ëª¨ë“œ ì‹¤í—˜ ê²°ê³¼ ë¡œë“œ (ìµœì‹  íŒŒì¼ ìë™ ê²€ìƒ‰)"""
    print("ğŸ“Š Demo ëª¨ë“œ ì‹¤í—˜ ê²°ê³¼ ë¡œë“œ ì¤‘...")
    
    # ìµœì‹  demo ì‹¤í—˜ íŒŒì¼ë“¤ ì°¾ê¸°
    experiment_files = glob.glob('factorial_results/factorial_experiment_data_demo_*.csv')
    analysis_files = glob.glob('factorial_results/factorial_analysis_data_demo_*.csv')
    summary_files = glob.glob('factorial_results/factorial_experiment_summary_demo_*.json')
    
    if not experiment_files:
        raise FileNotFoundError("Demo ì‹¤í—˜ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
    latest_experiment = max(experiment_files, key=os.path.getmtime)
    latest_analysis = max(analysis_files, key=os.path.getmtime) if analysis_files else None
    latest_summary = max(summary_files, key=os.path.getmtime) if summary_files else None
    
    print(f"ğŸ“ ë¡œë“œí•  íŒŒì¼ë“¤:")
    print(f"   - ì‹¤í—˜ ë°ì´í„°: {latest_experiment}")
    print(f"   - ë¶„ì„ ë°ì´í„°: {latest_analysis}")
    print(f"   - ìš”ì•½ í†µê³„: {latest_summary}")
    
    # ì‹¤í—˜ ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(latest_experiment)
    
    # factor_combination ë¬¸ìì—´ì„ íŒŒì‹±í•´ì„œ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„í•´
    print("ğŸ”§ ìš”ì¸ ì¡°í•© íŒŒì‹± ì¤‘...")
    
    # factor_combinationì„ JSONìœ¼ë¡œ íŒŒì‹± (ë¬¸ìì—´ì´ dict í˜•íƒœë¡œ ì €ì¥ë¨)
    factor_columns = []
    for idx, row in df.iterrows():
        try:
            # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            factor_dict = ast.literal_eval(row['factor_combination'])
            factor_columns.append(factor_dict)
        except:
            # ì‹¤íŒ¨í•˜ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬
            factor_columns.append({})
    
    # ìš”ì¸ë³„ë¡œ ì»¬ëŸ¼ ìƒì„±
    factor_df = pd.DataFrame(factor_columns)
    
    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ê³¼ ë³‘í•©
    for col in factor_df.columns:
        df[col] = factor_df[col]
    
    print(f"âœ… ìš”ì¸ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ: {list(factor_df.columns)}")
    
    # ë¶„ì„ ë°ì´í„° ë¡œë“œ (ìˆëŠ” ê²½ìš°)
    analysis_df = None
    if latest_analysis:
        analysis_df = pd.read_csv(latest_analysis)
    
    # ìš”ì•½ í†µê³„ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
    summary = None
    if latest_summary:
        with open(latest_summary, 'r', encoding='utf-8') as f:
            summary = json.load(f)
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"   - ì‹¤í—˜ ë°ì´í„°: {len(df)}ê°œ ê´€ì¸¡ì¹˜")
    if analysis_df is not None:
        print(f"   - ë¶„ì„ ë°ì´í„°: {len(analysis_df)}ê°œ ê´€ì¸¡ì¹˜")
    print(f"   - ìš”ì¸ ì»¬ëŸ¼: {[col for col in df.columns if col in ['prompt_language', 'model', 'role_assignment', 'explicitness']]}")
    
    return df, analysis_df, summary

def calculate_effect_sizes(df):
    """ìš”ì¸ë³„ íš¨ê³¼ í¬ê¸° ê³„ì‚° (Cohen's d)"""
    print("\nğŸ“ˆ ìš”ì¸ë³„ íš¨ê³¼ í¬ê¸° ê³„ì‚°")
    print("=" * 50)
    
    effect_sizes = {}
    
    # ê° ìš”ì¸ë³„ë¡œ Cohen's d ê³„ì‚°
    factors = ['prompt_language', 'model', 'role_assignment', 'explicitness']
    
    for factor in factors:
        groups = df.groupby(factor)['bert_multilingual_similarity']
        
        if len(groups) == 2:  # 2ìˆ˜ì¤€ ìš”ì¸
            group_names = list(groups.groups.keys())
            group1 = groups.get_group(group_names[0])
            group2 = groups.get_group(group_names[1])
            
            # Cohen's d ê³„ì‚°
            pooled_std = np.sqrt(((len(group1) - 1) * group1.var() + 
                                (len(group2) - 1) * group2.var()) / 
                               (len(group1) + len(group2) - 2))
            
            cohens_d = abs(group1.mean() - group2.mean()) / pooled_std
            
            effect_sizes[factor] = {
                'cohens_d': cohens_d,
                'mean_diff': abs(group1.mean() - group2.mean()),
                'group1_mean': group1.mean(),
                'group2_mean': group2.mean(),
                'pooled_std': pooled_std,
                'interpretation': interpret_effect_size(cohens_d)
            }
            
            print(f"ğŸ¯ {factor}:")
            print(f"   Cohen's d: {cohens_d:.4f} ({effect_sizes[factor]['interpretation']})")
            print(f"   í‰ê·  ì°¨ì´: {effect_sizes[factor]['mean_diff']:.4f}")
            print(f"   ê·¸ë£¹ í‰ê· : {group1.mean():.4f} vs {group2.mean():.4f}")
    
    # ì¹´í…Œê³ ë¦¬ íš¨ê³¼ (3ìˆ˜ì¤€)
    category_groups = df.groupby('category')['bert_multilingual_similarity']
    category_means = [group.mean() for _, group in category_groups]
    category_effect = (max(category_means) - min(category_means)) / df['bert_multilingual_similarity'].std()
    
    effect_sizes['category'] = {
        'effect_size': category_effect,
        'interpretation': interpret_effect_size(category_effect),
        'means': {name: group.mean() for name, group in category_groups}
    }
    
    print(f"ğŸ¯ category:")
    print(f"   Effect size: {category_effect:.4f} ({effect_sizes['category']['interpretation']})")
    print(f"   ì¹´í…Œê³ ë¦¬ë³„ í‰ê· : {effect_sizes['category']['means']}")
    
    return effect_sizes

def interpret_effect_size(d):
    """Effect size í•´ì„"""
    if d < 0.2:
        return "ë§¤ìš° ì‘ìŒ"
    elif d < 0.5:
        return "ì‘ìŒ"
    elif d < 0.8:
        return "ì¤‘ê°„"
    else:
        return "í° íš¨ê³¼"

def power_analysis_for_factors(effect_sizes, alpha=0.05):
    """ìš”ì¸ë³„ power analysis"""
    print(f"\nâš¡ Power Analysis (Î± = {alpha})")
    print("=" * 50)
    
    power_results = {}
    
    # ëª©í‘œ power ìˆ˜ì¤€ë“¤
    target_powers = [0.8, 0.9, 0.95]
    
    for factor, effect_data in effect_sizes.items():
        if factor == 'category':
            continue  # ì¹´í…Œê³ ë¦¬ëŠ” ë³„ë„ ì²˜ë¦¬
            
        cohens_d = effect_data['cohens_d']
        
        print(f"\nğŸ¯ {factor} (Cohen's d = {cohens_d:.4f})")
        
        factor_results = {}
        
        for power in target_powers:
            # t-testì— í•„ìš”í•œ ìƒ˜í”Œ í¬ê¸° ê³„ì‚° (ê°„ë‹¨í•œ ê³µì‹ ì‚¬ìš©)
            # Cohen's power tables ê¸°ë°˜ ê·¼ì‚¬ì‹
            if power == 0.8:
                if cohens_d < 0.2:
                    n_per_group = 400  # ë§¤ìš° ì‘ì€ íš¨ê³¼
                elif cohens_d < 0.5:
                    n_per_group = 64   # ì‘ì€ íš¨ê³¼
                elif cohens_d < 0.8:
                    n_per_group = 26   # ì¤‘ê°„ íš¨ê³¼  
                else:
                    n_per_group = 17   # í° íš¨ê³¼
            elif power == 0.9:
                if cohens_d < 0.2:
                    n_per_group = 526
                elif cohens_d < 0.5:
                    n_per_group = 85
                elif cohens_d < 0.8:
                    n_per_group = 34
                else:
                    n_per_group = 22
            else:  # power == 0.95
                if cohens_d < 0.2:
                    n_per_group = 651
                elif cohens_d < 0.5:
                    n_per_group = 105
                elif cohens_d < 0.8:
                    n_per_group = 42
                else:
                    n_per_group = 27
            
            # ë” ì •í™•í•œ ê³„ì‚° (scipy ì‚¬ìš©)
            try:
                from scipy.stats import norm
                z_alpha = norm.ppf(1 - alpha/2)  # ì–‘ì¸¡ê²€ì •
                z_beta = norm.ppf(power)
                n_per_group = ((z_alpha + z_beta) / cohens_d) ** 2
            except:
                pass  # ìœ„ì˜ ê·¼ì‚¬ê°’ ì‚¬ìš©
            
            total_n = n_per_group * 2
            
            # 2^4 factorialì—ì„œ í•„ìš”í•œ ì´ ì¡°ê±´ ìˆ˜ ê³„ì‚°
            # 16ê°œ ì¡°í•© ì¤‘ ì ˆë°˜ì”©ì´ ê° ìˆ˜ì¤€ì— í•´ë‹¹
            total_conditions = total_n * 8  # 16/2 = 8ê°œ ì¡°í•©ì”©
            
            # ì¹´í…Œê³ ë¦¬ ê³ ë ¤ (3ê°œ)
            total_with_categories = total_conditions * 3
            
            factor_results[power] = {
                'n_per_group': n_per_group,
                'total_n': total_n,
                'total_conditions': total_conditions,
                'total_with_categories': total_with_categories
            }
            
            print(f"   Power {power}: ê·¸ë£¹ë‹¹ {n_per_group:.1f}ê°œ, ì´ {total_with_categories:.0f}ê°œ ì¡°ê±´")
        
        power_results[factor] = factor_results
    
    return power_results

def cost_analysis(power_results, cost_per_condition=0.01):
    """ë¹„ìš© ë¶„ì„"""
    print(f"\nğŸ’° ë¹„ìš© ë¶„ì„ (ì¡°ê±´ë‹¹ ${cost_per_condition})")
    print("=" * 50)
    
    cost_analysis_results = {}
    
    for factor, power_data in power_results.items():
        print(f"\nğŸ¯ {factor}:")
        
        factor_costs = {}
        for power, sample_data in power_data.items():
            total_cost = sample_data['total_with_categories'] * cost_per_condition
            factor_costs[power] = total_cost
            
            print(f"   Power {power}: ${total_cost:.2f} (ì¡°ê±´ {sample_data['total_with_categories']:.0f}ê°œ)")
        
        cost_analysis_results[factor] = factor_costs
    
    return cost_analysis_results

def current_power_analysis(effect_sizes, current_n=96):
    """í˜„ì¬ ìƒ˜í”Œ í¬ê¸°(96)ì—ì„œì˜ power ê³„ì‚°"""
    print(f"\nğŸ” í˜„ì¬ ì„¤ê³„ì˜ Power ë¶„ì„ (n={current_n})")
    print("=" * 50)
    
    current_powers = {}
    
    for factor, effect_data in effect_sizes.items():
        if factor == 'category':
            continue
            
        cohens_d = effect_data['cohens_d']
        
        # í˜„ì¬ ê·¸ë£¹ë‹¹ ìƒ˜í”Œ í¬ê¸° (96ê°œ ì¡°ê±´ì˜ ì ˆë°˜ì”©)
        n_per_group = current_n / 2
        
        # í˜„ì¬ power ê³„ì‚° - ì˜¬ë°”ë¥¸ íŒŒë¼ë¯¸í„°ë§Œ ì‚¬ìš©
        current_power = ttest_power(effect_size=cohens_d, nobs=n_per_group, alpha=0.05, alternative='two-sided')
        
        current_powers[factor] = current_power
        
        print(f"ğŸ¯ {factor}:")
        print(f"   Effect size (Cohen's d): {cohens_d:.4f}")
        print(f"   í˜„ì¬ Power: {current_power:.3f}")
        print(f"   Power ì¶©ë¶„ì„±: {'âœ… ì¶©ë¶„' if current_power >= 0.8 else 'âŒ ë¶€ì¡±'}")
    
    return current_powers

def plot_power_curves(effect_sizes):
    """Power curve ì‹œê°í™”"""
    print(f"\nğŸ“Š Power Curve ì‹œê°í™”")
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.flatten()
    
    sample_sizes = np.arange(10, 200, 5)
    
    factor_idx = 0
    for factor, effect_data in effect_sizes.items():
        if factor == 'category' or factor_idx >= 6:
            continue
            
        cohens_d = effect_data['cohens_d']
        
        # ê° ìƒ˜í”Œ í¬ê¸°ì— ëŒ€í•œ power ê³„ì‚°
        powers = []
        for n in sample_sizes:
            power = ttest_power(effect_size=cohens_d, nobs=n/2, alpha=0.05, alternative='two-sided')
            powers.append(power)
        
        ax = axes[factor_idx]
        ax.plot(sample_sizes, powers, linewidth=2, label=f'{factor}')
        ax.axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='Power 0.8')
        ax.axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, label='Power 0.9')
        ax.axvline(x=96, color='green', linestyle='-', alpha=0.7, label='í˜„ì¬ ì„¤ê³„ (96)')
        
        ax.set_xlabel('ì´ ìƒ˜í”Œ í¬ê¸°')
        ax.set_ylabel('Statistical Power')
        ax.set_title(f'{factor}\n(Cohen\'s d = {cohens_d:.3f})')
        ax.grid(True, alpha=0.3)
        ax.legend()
        ax.set_ylim(0, 1)
        
        factor_idx += 1
    
    # ë¹ˆ subplot ì œê±°
    for i in range(factor_idx, 6):
        fig.delaxes(axes[i])
    
    plt.tight_layout()
    plt.savefig('factorial_results/power_curves.png', dpi=300, bbox_inches='tight')
    plt.show()

def generate_recommendations(effect_sizes, power_results, current_powers):
    """ì‹¤í—˜ ì„¤ê³„ ì¶”ì²œì•ˆ ìƒì„±"""
    print(f"\nğŸ¯ ì‹¤í—˜ ì„¤ê³„ ì¶”ì²œì•ˆ")
    print("=" * 60)
    
    # íš¨ê³¼ í¬ê¸°ë³„ ìš”ì¸ ë¶„ë¥˜
    large_effects = []
    medium_effects = []
    small_effects = []
    
    for factor, effect_data in effect_sizes.items():
        if factor == 'category':
            continue
        
        cohens_d = effect_data['cohens_d']
        if cohens_d >= 0.8:
            large_effects.append(factor)
        elif cohens_d >= 0.5:
            medium_effects.append(factor)
        elif cohens_d >= 0.2:
            small_effects.append(factor)
    
    print(f"ğŸ“Š íš¨ê³¼ í¬ê¸°ë³„ ìš”ì¸ ë¶„ë¥˜:")
    print(f"   í° íš¨ê³¼ (dâ‰¥0.8): {large_effects}")
    print(f"   ì¤‘ê°„ íš¨ê³¼ (0.5â‰¤d<0.8): {medium_effects}")  
    print(f"   ì‘ì€ íš¨ê³¼ (0.2â‰¤d<0.5): {small_effects}")
    
    # í˜„ì¬ powerê°€ ë¶€ì¡±í•œ ìš”ì¸ë“¤
    insufficient_power = [factor for factor, power in current_powers.items() if power < 0.8]
    
    print(f"\nâš¡ Power ë¶„ì„ ê²°ê³¼:")
    print(f"   Power ë¶€ì¡± ìš”ì¸: {insufficient_power}")
    print(f"   Power ì¶©ë¶„ ìš”ì¸: {[f for f in current_powers.keys() if f not in insufficient_power]}")
    
    # ì¶”ì²œì•ˆ
    print(f"\nğŸ’¡ ì¶”ì²œì•ˆ:")
    
    if not insufficient_power:
        print("   âœ… í˜„ì¬ Representative ì„¤ê³„(96ê°œ ì¡°ê±´)ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤!")
        print("   âœ… ëª¨ë“  ì£¼ìš” ìš”ì¸ì— ëŒ€í•´ ì ì ˆí•œ statistical powerë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
        recommendation = "representative"
    elif len(insufficient_power) <= 2:
        print("   ğŸ“ˆ Test ì„¤ê³„ë¥¼ Representative ì„¤ê³„ë¡œ í™•ì¥í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.")
        print("   ğŸ“ˆ í˜„ì¬ ì„¤ê³„ê°€ ëŒ€ë¶€ë¶„ ìš”ì¸ì— ì¶©ë¶„í•œ powerë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        recommendation = "representative"
    else:
        print("   ğŸ“ˆ Full ì„¤ê³„(480ê°œ ì¡°ê±´)ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        print("   ğŸ“ˆ ë” ë§ì€ ìš”ì¸ì— ëŒ€í•´ ì¶©ë¶„í•œ statistical powerê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        recommendation = "full"
    
    # ë¹„ìš© íš¨ìœ¨ì„±
    print(f"\nğŸ’° ë¹„ìš© íš¨ìœ¨ì„±:")
    print(f"   Representative (96ì¡°ê±´): ~$0.40")
    print(f"   Full (480ì¡°ê±´): ~$2.00")
    print(f"   ì¶”ì²œ: {recommendation} ì„¤ê³„")
    
    return {
        'large_effects': large_effects,
        'medium_effects': medium_effects,
        'small_effects': small_effects,
        'insufficient_power': insufficient_power,
        'recommendation': recommendation
    }

def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    print("ğŸ”¬ 2^4 Factorial Design Power Analysis")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    df, analysis_df, summary = load_demo_results()
    
    # 2. íš¨ê³¼ í¬ê¸° ê³„ì‚°
    effect_sizes = calculate_effect_sizes(df)
    
    # 3. Power analysis
    power_results = power_analysis_for_factors(effect_sizes)
    
    # 4. ë¹„ìš© ë¶„ì„
    cost_results = cost_analysis(power_results)
    
    # 5. í˜„ì¬ ì„¤ê³„ì˜ power ë¶„ì„
    current_powers = current_power_analysis(effect_sizes)
    
    # 6. Power curve ì‹œê°í™”
    plot_power_curves(effect_sizes)
    
    # 7. ì¶”ì²œì•ˆ ìƒì„±
    recommendations = generate_recommendations(effect_sizes, power_results, current_powers)
    
    # 8. ê²°ê³¼ ì €ì¥
    results = {
        'effect_sizes': effect_sizes,
        'power_results': power_results,
        'cost_results': cost_results,
        'current_powers': current_powers,
        'recommendations': recommendations
    }
    
    # JSONìœ¼ë¡œ ì €ì¥ (numpy íƒ€ì… ì²˜ë¦¬)
    def convert_numpy(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.integer):
            return int(obj)
        return obj
    
    with open('factorial_results/power_analysis_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=convert_numpy)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
    print(f"   ğŸ“Š Power curves: factorial_results/power_curves.png")
    print(f"   ğŸ“„ ë¶„ì„ ê²°ê³¼: factorial_results/power_analysis_results.json")
    
    return results

if __name__ == "__main__":
    results = main() 